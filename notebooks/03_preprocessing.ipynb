{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04d99e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbfde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/Silver/df_reduced.parquet\") \n",
    "# df = pd.read_parquet(\"s3://bass-risk-monitoring/Bronze/df_reduced.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "375dd31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31898238, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1324a5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "5a6e7922-c5eb-49ac-b001-367bfe680f58",
       "rows": [
        [
         "Timestamp",
         "datetime64[ns]"
        ],
        [
         "From Bank",
         "int32"
        ],
        [
         "Account",
         "string"
        ],
        [
         "To Bank",
         "int32"
        ],
        [
         "Account.1",
         "string"
        ],
        [
         "Amount Received",
         "float64"
        ],
        [
         "Receiving Currency",
         "category"
        ],
        [
         "Amount Paid",
         "float64"
        ],
        [
         "Payment Currency",
         "category"
        ],
        [
         "Payment Format",
         "category"
        ],
        [
         "Is Laundering",
         "int8"
        ],
        [
         "log_amount_paid",
         "float64"
        ],
        [
         "hour",
         "int32"
        ],
        [
         "date",
         "object"
        ],
        [
         "month",
         "period[M]"
        ],
        [
         "day_of_week",
         "int32"
        ],
        [
         "is_weekend",
         "int64"
        ],
        [
         "daily_txn_count",
         "int64"
        ],
        [
         "time_since_last_txn",
         "float64"
        ],
        [
         "txn_count_24h_excl",
         "int32"
        ],
        [
         "amount_ratio",
         "float64"
        ],
        [
         "currency_diversity",
         "int64"
        ],
        [
         "format_diversity",
         "int64"
        ],
        [
         "unique_receivers",
         "int64"
        ],
        [
         "is_self_transfer",
         "int8"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 25
       }
      },
      "text/plain": [
       "Timestamp              datetime64[ns]\n",
       "From Bank                       int32\n",
       "Account                string[python]\n",
       "To Bank                         int32\n",
       "Account.1              string[python]\n",
       "Amount Received               float64\n",
       "Receiving Currency           category\n",
       "Amount Paid                   float64\n",
       "Payment Currency             category\n",
       "Payment Format               category\n",
       "Is Laundering                    int8\n",
       "log_amount_paid               float64\n",
       "hour                            int32\n",
       "date                           object\n",
       "month                       period[M]\n",
       "day_of_week                     int32\n",
       "is_weekend                      int64\n",
       "daily_txn_count                 int64\n",
       "time_since_last_txn           float64\n",
       "txn_count_24h_excl              int32\n",
       "amount_ratio                  float64\n",
       "currency_diversity              int64\n",
       "format_diversity                int64\n",
       "unique_receivers                int64\n",
       "is_self_transfer                 int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d928f1",
   "metadata": {},
   "source": [
    "features for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "868ad429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['log_amount_paid', 'hour', 'day_of_week', 'is_weekend', 'daily_txn_count', 'time_since_last_txn', 'txn_count_24h_excl', 'amount_ratio', 'currency_diversity', 'format_diversity', 'unique_receivers', 'is_self_transfer', 'Receiving Currency', 'Payment Currency', 'Payment Format', 'Is Laundering', 'Timestamp']\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "UTIL = ['Timestamp']\n",
    "\n",
    "TARGET = \"Is Laundering\"\n",
    "CATEGORICAL = ['Receiving Currency', 'Payment Currency', 'Payment Format']\n",
    "\n",
    "ID_LIKE = ['Account', 'Account.1', 'From Bank', 'To Bank']\n",
    "DROP_RAW_AMOUNTS = ['Amount Paid', 'Amount Received']\n",
    "\n",
    "#  numeric\n",
    "num_all = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "NUMERIC = [c for c in num_all if c not in ([TARGET] + ID_LIKE)]\n",
    "NUMERIC = [c for c in NUMERIC if c not in DROP_RAW_AMOUNTS]\n",
    "\n",
    "\n",
    "KEEP = list(dict.fromkeys(NUMERIC + CATEGORICAL + [TARGET] + UTIL))\n",
    "df = df[KEEP].copy()\n",
    "print( df.columns.tolist())\n",
    "print( len(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b4b10",
   "metadata": {},
   "source": [
    "#### Time-based split (60/20/20) and laundering rates\n",
    "\n",
    "AML patterns evolve over time.\n",
    "we will train on earlier normal behavior and testing on later data simulates real monitoring conditions and avoids future information leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1659314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chronological order\n",
    "df = df.sort_values(\"Timestamp\").reset_index(drop=True)\n",
    "\n",
    "t1 = df[\"Timestamp\"].quantile(0.60)\n",
    "t2 = df[\"Timestamp\"].quantile(0.80)\n",
    "\n",
    "train_df = df[df[\"Timestamp\"] <= t1].copy()\n",
    "val_df   = df[(df[\"Timestamp\"] > t1) & (df[\"Timestamp\"] <= t2)].copy()\n",
    "test_df  = df[df[\"Timestamp\"] >  t2].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e091a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Laundering rates\n",
      "Train | shape=(19139453, 17) | positives=15536 | rate=0.1%\n",
      "Val   | shape=(6379894, 17) | positives=9054 | rate=0.1%\n",
      "Test  | shape=(6378891, 17) | positives=10640 | rate=0.2%\n"
     ]
    }
   ],
   "source": [
    "def summarize(name, d, target=\"Is Laundering\"):\n",
    "    n = len(d)\n",
    "    pos = int(d[target].sum())\n",
    "    rate = 100.0 * pos / n if n else 0.0\n",
    "    print(f\"{name:5s} | shape={d.shape} | positives={pos} | rate={rate:.1f}%\")\n",
    "\n",
    "print(\" Laundering rates\")\n",
    "summarize(\"Train\", train_df)\n",
    "summarize(\"Val\",   val_df)\n",
    "summarize(\"Test\",  test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b9caddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> Train: (19139453, 15) | Val: (6379894, 15) | Test: (6378891, 15)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FEATURES = NUMERIC + CATEGORICAL \n",
    "\n",
    "X_train, y_train = train_df[FEATURES].copy(), train_df[TARGET].astype(\"int8\")\n",
    "X_val,   y_val   = val_df[FEATURES].copy(),   val_df[TARGET].astype(\"int8\")\n",
    "X_test,  y_test  = test_df[FEATURES].copy(),  test_df[TARGET].astype(\"int8\")\n",
    "\n",
    "print(\"Shapes -> Train:\", X_train.shape, \"| Val:\", X_val.shape, \"| Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9594ec",
   "metadata": {},
   "source": [
    "Encoding and scalling training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "691c536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(with_mean=False), NUMERIC),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), CATEGORICAL),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=1.0,  \n",
    "    verbose_feature_names_out=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd55abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pre = preprocessor.fit_transform(X_train)\n",
    "X_val_pre   = preprocessor.transform(X_val)\n",
    "X_test_pre  = preprocessor.transform(X_test)\n",
    "try:\n",
    "    feat_names = preprocessor.get_feature_names_out()\n",
    "except Exception:\n",
    "    feat_names = np.array([f\"f{i}\" for i in range(X_train_pre.shape[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e78784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared shapes: (19139453, 49) (6379894, 49) (6378891, 49)\n",
      "Sparse matrix? -> False\n"
     ]
    }
   ],
   "source": [
    "print(\"Prepared shapes:\", X_train_pre.shape, X_val_pre.shape, X_test_pre.shape)\n",
    "print(\"Sparse matrix? ->\", hasattr(X_train_pre, \"tocsr\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5647534",
   "metadata": {},
   "source": [
    "Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "126ce805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.int64(0): np.float64(0.5004061929363112),\n",
       " np.int64(1): np.float64(615.9710671987642)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clases_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "classes = np.array([0, 1], dtype=int)\n",
    "weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "class_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30454a",
   "metadata": {},
   "source": [
    "Save artifacts & splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a3eeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/models/X_test_pre.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(preprocessor, \"../data/models/preprocessor.joblib\")\n",
    "joblib.dump(NUMERIC, \"../data/models/numeric_cols.joblib\")\n",
    "joblib.dump(CATEGORICAL, \"../data/models/categorical_cols.joblib\")\n",
    "\n",
    "joblib.dump(feat_names, \"../data/models/prepared_feature_names.joblib\")\n",
    "joblib.dump(class_weights,\"../data/models/class_weights.joblib\")\n",
    "\n",
    "pd.DataFrame(y_train).to_parquet(\"../data/Gold/y_train.parquet\", index=False)\n",
    "pd.DataFrame(y_val).to_parquet(\"../data/Gold/y_val.parquet\",   index=False)\n",
    "pd.DataFrame(y_test).to_parquet(\"../data/Gold/y_test.parquet\",  index=False)\n",
    "\n",
    "joblib.dump(X_train_pre,\"../data/models/X_train_pre.joblib\")\n",
    "joblib.dump(X_val_pre, \"../data/models/X_val_pre.joblib\")\n",
    "joblib.dump(X_test_pre, \"../data/models/X_test_pre.joblib\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
